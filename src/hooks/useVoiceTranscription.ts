
// Nada mudou, mantendo arquivo como est√°
import { useState } from 'react';
import { useToast } from '@/hooks/use-toast';
import { useClientConfig } from '@/contexts/ClientConfigContext';

export function useVoiceTranscription() {
  const [isTranscribing, setIsTranscribing] = useState(false);
  const { toast } = useToast();
  const { config } = useClientConfig();

  const transcribeAudio = async (audioBase64: string): Promise<string | null> => {
    setIsTranscribing(true);
    
    try {
      console.log('üîÑ Iniciando transcri√ß√£o:', {
        audioSize: audioBase64.length,
        audioPreview: audioBase64.substring(0, 50),
        timestamp: new Date().toISOString()
      });
      
      // Validar entrada rigorosamente
      if (!audioBase64 || audioBase64.length === 0) {
        throw new Error('Dados de √°udio inv√°lidos ou vazios');
      }

      if (audioBase64.length < 100) {
        throw new Error('Dados de √°udio muito pequenos - poss√≠vel corrup√ß√£o');
      }

      // Verificar se √© base64 v√°lido
      try {
        const testDecode = atob(audioBase64.substring(0, 100));
        console.log('‚úÖ Base64 v√°lido confirmado');
      } catch (decodeError) {
        console.error('‚ùå Base64 inv√°lido:', decodeError);
        throw new Error('Dados de √°udio corrompidos - formato inv√°lido');
      }

      // Verificar configura√ß√£o OpenAI
      const hasValidApiKey = config.openai?.apiKey && config.openai.apiKey.startsWith('sk-');
      
      if (hasValidApiKey) {
        console.log('üîÑ Usando OpenAI API diretamente...');
        return await transcribeWithOpenAI(audioBase64, config.openai.apiKey);
      } else {
        console.log('üîÑ Usando edge function como fallback...');
        return await transcribeWithEdgeFunction(audioBase64);
      }

    } catch (error) {
      console.error('‚ùå Erro geral na transcri√ß√£o:', error);
      
      const errorMessage = error instanceof Error ? error.message : 'Erro desconhecido na transcri√ß√£o';
      
      toast({
        title: "‚ùå Erro na transcri√ß√£o",
        description: errorMessage,
        variant: "destructive",
      });
      
      return null;
    } finally {
      setIsTranscribing(false);
    }
  };

  const transcribeWithOpenAI = async (audioBase64: string, apiKey: string): Promise<string> => {
    try {
      console.log('ü§ñ Processando com OpenAI direta:', {
        apiKeyPrefix: apiKey.substring(0, 10) + '...',
        audioSize: audioBase64.length
      });

      // Converter base64 com valida√ß√£o detalhada
      const binaryString = atob(audioBase64);
      console.log('üìä Dados bin√°rios:', {
        binaryLength: binaryString.length,
        sizeKB: Math.round(binaryString.length / 1024)
      });
      
      if (binaryString.length === 0) {
        throw new Error('Dados de √°udio corrompidos ap√≥s decodifica√ß√£o');
      }

      // Converter para Uint8Array
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      
      // Criar blob com tipo espec√≠fico
      const audioBlob = new Blob([bytes], { type: 'audio/webm' });
      console.log('üìÑ Blob final para OpenAI:', { 
        size: audioBlob.size, 
        type: audioBlob.type,
        sizeKB: Math.round(audioBlob.size / 1024)
      });
      
      if (audioBlob.size === 0) {
        throw new Error('Arquivo de √°udio vazio ap√≥s convers√£o');
      }

      // Verificar tamanho m√°ximo (25MB limite da OpenAI)
      const maxSize = 25 * 1024 * 1024;
      if (audioBlob.size > maxSize) {
        throw new Error(`Arquivo muito grande (${Math.round(audioBlob.size / 1024 / 1024)}MB). M√°ximo: 25MB`);
      }

      // Preparar FormData com configura√ß√µes espec√≠ficas
      const formData = new FormData();
      formData.append('file', audioBlob, 'recording.webm');
      formData.append('model', 'whisper-1');
      formData.append('language', 'pt'); // For√ßar portugu√™s
      formData.append('response_format', 'json');
      formData.append('temperature', '0'); // Menor criatividade para maior precis√£o

      console.log('üì§ Enviando para OpenAI Whisper...');

      // Fazer requisi√ß√£o com timeout
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 30000);

      try {
        const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
          },
          body: formData,
          signal: controller.signal,
        });

        clearTimeout(timeoutId);
        
        console.log('üì° Resposta OpenAI:', {
          status: response.status,
          statusText: response.statusText,
          headers: Object.fromEntries(response.headers.entries())
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error('‚ùå Erro detalhado OpenAI:', {
            status: response.status,
            statusText: response.statusText,
            errorBody: errorText
          });
          
          let errorMessage = `Erro da OpenAI (${response.status})`;
          
          if (response.status === 400) {
            errorMessage = 'Formato de √°udio n√£o suportado ou dados corrompidos';
          } else if (response.status === 401) {
            errorMessage = 'API key da OpenAI inv√°lida ou expirada';
          } else if (response.status === 429) {
            errorMessage = 'Limite de uso da OpenAI atingido - tente novamente em alguns minutos';
          } else if (response.status >= 500) {
            errorMessage = 'Erro interno da OpenAI - tente novamente em alguns minutos';
          }
          
          throw new Error(errorMessage);
        }

        const result = await response.json();
        console.log('üìÑ Resultado completo OpenAI:', {
          text: result.text,
          language: result.language,
          duration: result.duration,
          segments: result.segments ? result.segments.length : 'N/A'
        });

        if (!result.text || result.text.trim().length === 0) {
          throw new Error('Transcri√ß√£o vazia - √°udio pode estar mudo ou corrompido');
        }

        // Verificar se o resultado faz sentido (evitar textos estranhos)
        const transcribedText = result.text.trim();
        
        if (transcribedText.toLowerCase().includes('amara.org') || 
            transcribedText.toLowerCase().includes('legendada pela comunidade')) {
          console.warn('‚ö†Ô∏è Texto suspeito detectado:', transcribedText);
          throw new Error('Transcri√ß√£o retornou texto inv√°lido - tente gravar novamente');
        }

        console.log('‚úÖ Transcri√ß√£o v√°lida:', transcribedText.substring(0, 100) + '...');

        toast({
          title: "‚úÖ Transcri√ß√£o conclu√≠da",
          description: `Transcrito via OpenAI: "${transcribedText.substring(0, 50)}${transcribedText.length > 50 ? '...' : ''}"`,
        });

        return transcribedText;
        
      } catch (fetchError) {
        clearTimeout(timeoutId);
        
        if (fetchError.name === 'AbortError') {
          throw new Error('Transcri√ß√£o demorou muito - tente um √°udio mais curto');
        }
        
        throw fetchError;
      }
      
    } catch (error) {
      console.error('‚ùå Erro detalhado na API OpenAI:', error);
      throw error;
    }
  };

  const transcribeWithEdgeFunction = async (audioBase64: string): Promise<string> => {
    try {
      console.log('üåê Usando edge function:', {
        audioSize: audioBase64.length,
        endpoint: '/functions/v1/voice-to-text'
      });

      const response = await fetch('/functions/v1/voice-to-text', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${import.meta.env.VITE_SUPABASE_ANON_KEY || ''}`,
        },
        body: JSON.stringify({
          audioBase64: audioBase64
        }),
      });

      console.log('üì° Resposta edge function:', {
        status: response.status,
        statusText: response.statusText
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erro edge function:', {
          status: response.status,
          errorBody: errorText
        });
        throw new Error(`Erro na edge function (${response.status}): ${errorText}`);
      }

      const data = await response.json();
      console.log('üìÑ Dados da edge function:', data);
      
      if (data.error) {
        throw new Error(data.error);
      }

      if (!data.text || data.text.trim().length === 0) {
        throw new Error('Edge function retornou transcri√ß√£o vazia');
      }

      const transcribedText = data.text.trim();

      // Verificar texto suspeito tamb√©m na edge function
      if (transcribedText.toLowerCase().includes('amara.org') || 
          transcribedText.toLowerCase().includes('legendada pela comunidade')) {
        console.warn('‚ö†Ô∏è Texto suspeito da edge function:', transcribedText);
        throw new Error('Edge function retornou texto inv√°lido - problema na transcri√ß√£o');
      }

      console.log('‚úÖ Transcri√ß√£o edge function v√°lida:', transcribedText.substring(0, 100) + '...');
      
      toast({
        title: "‚úÖ Transcri√ß√£o conclu√≠da",
        description: `Transcrito via servidor: "${transcribedText.substring(0, 50)}${transcribedText.length > 50 ? '...' : ''}"`,
      });

      return transcribedText;
    } catch (error) {
      console.error('‚ùå Erro na edge function:', error);
      throw new Error('Servidor de transcri√ß√£o indispon√≠vel - configure OpenAI API key para transcri√ß√£o direta');
    }
  };

  return {
    transcribeAudio,
    isTranscribing
  };
}

