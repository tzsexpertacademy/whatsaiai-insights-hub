
import { useState } from 'react';
import { useToast } from '@/hooks/use-toast';
import { useClientConfig } from '@/contexts/ClientConfigContext';

export function useVoiceTranscription() {
  const [isTranscribing, setIsTranscribing] = useState(false);
  const { toast } = useToast();
  const { config } = useClientConfig();

  const transcribeAudio = async (audioBase64: string): Promise<string | null> => {
    setIsTranscribing(true);
    
    try {
      console.log('üîÑ Iniciando transcri√ß√£o:', {
        audioSize: audioBase64.length,
        audioPreview: audioBase64.substring(0, 50),
        timestamp: new Date().toISOString()
      });
      
      // Validar entrada
      if (!audioBase64 || audioBase64.length === 0) {
        throw new Error('Dados de √°udio inv√°lidos ou vazios');
      }

      if (audioBase64.length < 100) {
        throw new Error('Dados de √°udio muito pequenos');
      }

      // Verificar configura√ß√£o OpenAI
      const hasValidApiKey = config?.openai?.apiKey && config.openai.apiKey.startsWith('sk-');
      
      if (hasValidApiKey) {
        console.log('üîÑ Usando OpenAI API diretamente...');
        return await transcribeWithOpenAI(audioBase64, config.openai.apiKey);
      } else {
        console.log('üîÑ Usando edge function como fallback...');
        return await transcribeWithEdgeFunction(audioBase64);
      }

    } catch (error) {
      console.error('‚ùå Erro geral na transcri√ß√£o:', error);
      
      const errorMessage = error instanceof Error ? error.message : 'Erro desconhecido na transcri√ß√£o';
      
      toast({
        title: "‚ùå Erro na transcri√ß√£o",
        description: errorMessage,
        variant: "destructive",
      });
      
      return null;
    } finally {
      setIsTranscribing(false);
    }
  };

  const transcribeWithOpenAI = async (audioBase64: string, apiKey: string): Promise<string> => {
    try {
      console.log('ü§ñ Processando com OpenAI direta');

      // Converter base64 para blob
      const binaryString = atob(audioBase64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      
      const audioBlob = new Blob([bytes], { type: 'audio/webm' });
      
      if (audioBlob.size === 0) {
        throw new Error('Arquivo de √°udio vazio');
      }

      // Preparar FormData
      const formData = new FormData();
      formData.append('file', audioBlob, 'recording.webm');
      formData.append('model', 'whisper-1');
      formData.append('language', 'pt');
      formData.append('response_format', 'json');

      console.log('üì§ Enviando para OpenAI Whisper...');

      const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
        },
        body: formData,
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erro na OpenAI:', errorText);
        throw new Error(`Erro da OpenAI (${response.status})`);
      }

      const result = await response.json();
      
      if (!result.text || result.text.trim().length === 0) {
        throw new Error('Transcri√ß√£o vazia');
      }

      const transcribedText = result.text.trim();
      
      console.log('‚úÖ Transcri√ß√£o OpenAI v√°lida:', transcribedText.substring(0, 100) + '...');

      toast({
        title: "‚úÖ Transcri√ß√£o conclu√≠da",
        description: `OpenAI: "${transcribedText.substring(0, 50)}${transcribedText.length > 50 ? '...' : ''}"`,
      });

      return transcribedText;
      
    } catch (error) {
      console.error('‚ùå Erro na API OpenAI:', error);
      throw error;
    }
  };

  const transcribeWithEdgeFunction = async (audioBase64: string): Promise<string> => {
    try {
      console.log('üåê Usando edge function');

      const response = await fetch('/functions/v1/voice-to-text', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${import.meta.env.VITE_SUPABASE_ANON_KEY || ''}`,
        },
        body: JSON.stringify({
          audioBase64: audioBase64
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('‚ùå Erro edge function:', errorText);
        throw new Error(`Erro na edge function (${response.status})`);
      }

      const data = await response.json();
      
      if (data.error) {
        throw new Error(data.error);
      }

      if (!data.text || data.text.trim().length === 0) {
        throw new Error('Edge function retornou transcri√ß√£o vazia');
      }

      const transcribedText = data.text.trim();
      
      console.log('‚úÖ Transcri√ß√£o edge function v√°lida:', transcribedText.substring(0, 100) + '...');
      
      toast({
        title: "‚úÖ Transcri√ß√£o conclu√≠da",
        description: `Servidor: "${transcribedText.substring(0, 50)}${transcribedText.length > 50 ? '...' : ''}"`,
      });

      return transcribedText;
    } catch (error) {
      console.error('‚ùå Erro na edge function:', error);
      throw new Error('Servidor de transcri√ß√£o indispon√≠vel - configure OpenAI API key');
    }
  };

  return {
    transcribeAudio,
    isTranscribing
  };
}
