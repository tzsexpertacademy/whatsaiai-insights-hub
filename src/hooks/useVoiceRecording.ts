
import { useState, useRef, useCallback } from 'react';
import { useToast } from '@/hooks/use-toast';

interface UseVoiceRecordingReturn {
  isRecording: boolean;
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<string | null>;
  audioLevel: number;
}

export function useVoiceRecording(): UseVoiceRecordingReturn {
  const [isRecording, setIsRecording] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const { toast } = useToast();

  const cleanup = useCallback(() => {
    // Parar anima√ß√£o
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    // Fechar contexto de √°udio
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }

    // Parar todas as tracks do stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('üîá Track parada:', track.kind);
      });
      streamRef.current = null;
    }

    // Limpar MediaRecorder
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current = null;
    }

    setAudioLevel(0);
    console.log('üßπ Cleanup de √°udio completo');
  }, []);

  const startRecording = useCallback(async () => {
    try {
      console.log('üé§ Iniciando grava√ß√£o de √°udio...');
      
      if (isRecording) {
        console.warn('‚ö†Ô∏è J√° est√° gravando');
        return;
      }

      cleanup();

      // Solicitar permiss√£o do microfone com configura√ß√µes otimizadas
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000, // Mudan√ßa para 16kHz que √© o padr√£o do Whisper
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      streamRef.current = stream;
      console.log('üì∫ Stream de √°udio obtido');

      // Verificar formatos suportados em ordem de prefer√™ncia
      const mimeTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/mp4;codecs=mp4a.40.2',
        'audio/mp4',
        'audio/wav'
      ];

      let selectedMimeType = '';
      for (const mimeType of mimeTypes) {
        if (MediaRecorder.isTypeSupported(mimeType)) {
          selectedMimeType = mimeType;
          console.log('üéµ Formato selecionado:', mimeType);
          break;
        }
      }

      if (!selectedMimeType) {
        throw new Error('Nenhum formato de √°udio suportado pelo navegador');
      }

      // Configurar MediaRecorder
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: selectedMimeType,
        audioBitsPerSecond: 128000 // Qualidade adequada para transcri√ß√£o
      });

      audioChunksRef.current = [];

      // Configurar eventos do MediaRecorder
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log('üì¶ Chunk de √°udio recebido:', event.data.size, 'bytes');
        }
      };

      mediaRecorderRef.current.onerror = (event) => {
        console.error('‚ùå Erro no MediaRecorder:', event);
        toast({
          title: "Erro na grava√ß√£o",
          description: "Erro interno do gravador de √°udio",
          variant: "destructive",
        });
      };

      // Setup an√°lise de √°udio para feedback visual
      try {
        audioContextRef.current = new AudioContext();
        analyserRef.current = audioContextRef.current.createAnalyser();
        const source = audioContextRef.current.createMediaStreamSource(stream);
        source.connect(analyserRef.current);
        
        analyserRef.current.fftSize = 256;
        const bufferLength = analyserRef.current.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        const updateAudioLevel = () => {
          if (analyserRef.current && isRecording) {
            analyserRef.current.getByteFrequencyData(dataArray);
            const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
            const normalizedLevel = Math.min(average / 128, 1);
            setAudioLevel(normalizedLevel);
            animationFrameRef.current = requestAnimationFrame(updateAudioLevel);
          }
        };

        updateAudioLevel();
      } catch (audioContextError) {
        console.warn('‚ö†Ô∏è N√£o foi poss√≠vel criar contexto de √°udio para feedback visual:', audioContextError);
      }

      // Iniciar grava√ß√£o
      mediaRecorderRef.current.start(1000); // Coletar dados a cada segundo
      setIsRecording(true);

      console.log('‚úÖ Grava√ß√£o iniciada com sucesso');
      
      toast({
        title: "üé§ Grava√ß√£o iniciada",
        description: "Fale agora, sua voz est√° sendo gravada",
      });

    } catch (error) {
      console.error('‚ùå Erro ao iniciar grava√ß√£o:', error);
      
      cleanup();
      setIsRecording(false);
      
      let errorMessage = "N√£o foi poss√≠vel acessar o microfone";
      
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = "Permiss√£o de microfone negada. Permita o acesso ao microfone e tente novamente.";
        } else if (error.name === 'NotFoundError') {
          errorMessage = "Nenhum microfone encontrado. Conecte um microfone e tente novamente.";
        } else if (error.name === 'NotReadableError') {
          errorMessage = "Microfone est√° sendo usado por outro aplicativo.";
        }
      }
      
      toast({
        title: "‚ùå Erro na grava√ß√£o",
        description: errorMessage,
        variant: "destructive",
      });
    }
  }, [isRecording, toast, cleanup]);

  const stopRecording = useCallback(async (): Promise<string | null> => {
    return new Promise((resolve) => {
      if (!mediaRecorderRef.current || !isRecording) {
        console.warn('‚ö†Ô∏è Nenhuma grava√ß√£o ativa para parar');
        resolve(null);
        return;
      }

      console.log('üõë Parando grava√ß√£o...');

      mediaRecorderRef.current.onstop = async () => {
        try {
          if (audioChunksRef.current.length === 0) {
            throw new Error('Nenhum dado de √°udio foi capturado');
          }

          // Criar blob com o tipo MIME correto
          const mimeType = mediaRecorderRef.current?.mimeType || 'audio/webm';
          const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
          
          console.log('üìÑ √Åudio gravado:', {
            size: audioBlob.size,
            type: audioBlob.type,
            chunks: audioChunksRef.current.length
          });

          if (audioBlob.size === 0) {
            throw new Error('Arquivo de √°udio vazio');
          }

          // Verificar tamanho m√≠nimo (pelo menos 1KB)
          if (audioBlob.size < 1024) {
            throw new Error('√Åudio muito curto. Grave por pelo menos 1 segundo.');
          }

          // Converter blob para base64
          const reader = new FileReader();
          reader.onloadend = () => {
            try {
              const result = reader.result as string;
              if (!result || !result.includes(',')) {
                throw new Error('Erro na convers√£o do √°udio');
              }
              
              const base64Audio = result.split(',')[1]; // Remove o prefixo data:audio/...;base64,
              
              if (!base64Audio || base64Audio.length === 0) {
                throw new Error('√Åudio vazio ap√≥s convers√£o');
              }
              
              console.log('‚úÖ √Åudio convertido para base64, tamanho:', base64Audio.length);
              
              toast({
                title: "‚úÖ Grava√ß√£o conclu√≠da",
                description: "√Åudio processado com sucesso",
              });
              
              resolve(base64Audio);
            } catch (conversionError) {
              console.error('‚ùå Erro na convers√£o:', conversionError);
              toast({
                title: "‚ùå Erro no processamento",
                description: "Erro ao converter √°udio",
                variant: "destructive",
              });
              resolve(null);
            }
          };
          
          reader.onerror = () => {
            console.error('‚ùå Erro ao ler arquivo de √°udio');
            toast({
              title: "‚ùå Erro no processamento",
              description: "N√£o foi poss√≠vel processar o √°udio gravado",
              variant: "destructive",
            });
            resolve(null);
          };
          
          reader.readAsDataURL(audioBlob);

        } catch (error) {
          console.error('‚ùå Erro ao processar √°udio:', error);
          toast({
            title: "‚ùå Erro no processamento",
            description: error instanceof Error ? error.message : "Erro desconhecido ao processar √°udio",
            variant: "destructive",
          });
          resolve(null);
        } finally {
          cleanup();
        }
      };

      // Parar o MediaRecorder
      try {
        if (mediaRecorderRef.current.state === 'recording') {
          mediaRecorderRef.current.stop();
        }
      } catch (error) {
        console.error('‚ùå Erro ao parar MediaRecorder:', error);
        cleanup();
        resolve(null);
      }
      
      setIsRecording(false);
    });
  }, [isRecording, toast, cleanup]);

  return {
    isRecording,
    startRecording,
    stopRecording,
    audioLevel
  };
}
